{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","provenance":[],"mount_file_id":"13WZgcB8TuGlhWgV5iKk79qxF_fJ42RKE","authorship_tag":"ABX9TyNqzvvvKOgfJgOTK3pDslsN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"LmQo3pHD6oOC","executionInfo":{"status":"ok","timestamp":1649721585962,"user_tz":240,"elapsed":5894,"user":{"displayName":"Emmanuel Okafor","userId":"10399249480681526142"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b2ba91b8-e3dd-4ea9-d98d-0f75c367c624"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting simpleaudio\n","  Downloading simpleaudio-1.0.4.tar.gz (2.0 MB)\n","\u001b[K     |████████████████████████████████| 2.0 MB 14.8 MB/s \n","\u001b[?25hBuilding wheels for collected packages: simpleaudio\n","  Building wheel for simpleaudio (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for simpleaudio: filename=simpleaudio-1.0.4-cp37-cp37m-linux_x86_64.whl size=2065948 sha256=d18251ed50c93a1f64e1fc49cffe002fa833d43147d47e9f11aa5c71044ecb2c\n","  Stored in directory: /root/.cache/pip/wheels/9a/d6/39/e26b6f988cc5acd1fba2c1b18f0debe27bdee3e1e53f4c93f9\n","Successfully built simpleaudio\n","Installing collected packages: simpleaudio\n","Successfully installed simpleaudio-1.0.4\n"]}],"source":["!pip install simpleaudio\n","import tensorflow as tf\n","from keras.layers import LeakyReLU\n","from tensorflow.keras import datasets, layers, models\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import simpleaudio as sa\n","import matplotlib.pyplot as plt\n","import tensorflow as tf"]},{"cell_type":"code","source":["from keras.backend import dropout\n","model = models.Sequential()\n","model.add(layers.Input(shape=(128,43,1)))\n","model.add(layers.ZeroPadding2D(padding=(1,1),data_format='channels_last'))\n","model.add(layers.Conv2D(32, (3, 3), padding='same',activation=LeakyReLU()))\n","model.add(layers.ZeroPadding2D(padding=(1, 1), data_format=\"channels_last\"))\n","model.add(layers.Conv2D(32, (3, 3),padding='same',activation=LeakyReLU()))\n","model.add(layers.MaxPooling2D((3, 3)))\n","model.add(layers.Dropout(0.25))\n","model.add(layers.ZeroPadding2D(padding=(1, 1), data_format=\"channels_last\"))\n","model.add(layers.Conv2D(64, (3, 3),padding='same', activation=LeakyReLU()))\n","model.add(layers.ZeroPadding2D(padding=(1, 1), data_format=\"channels_last\"))\n","model.add(layers.Conv2D(64, (3, 3),padding='same',activation=LeakyReLU()))\n","model.add(layers.MaxPooling2D((3, 3)))\n","model.add(layers.Dropout(0.25))\n","model.add(layers.ZeroPadding2D(padding=(1, 1), data_format=\"channels_last\"))\n","model.add(layers.Conv2D(128, (3, 3), padding='same',activation=LeakyReLU()))\n","model.add(layers.ZeroPadding2D(padding=(1, 1), data_format=\"channels_last\"))\n","model.add(layers.Conv2D(128, (3, 3), padding='same',activation=LeakyReLU()))\n","model.add(layers.MaxPooling2D((3, 3)))\n","model.add(layers.Dropout(0.25))\n","model.add(layers.ZeroPadding2D(padding=(1, 1), data_format=\"channels_last\"))\n","model.add(layers.Conv2D(256, (3, 3), activation=LeakyReLU()))\n","model.add(layers.ZeroPadding2D(padding=(1,\n"," 1), data_format=\"channels_last\"))\n","model.add(layers.Conv2D(256, (3, 3), activation=LeakyReLU()))\n","model.add(layers.GlobalMaxPool2D())\n","model.add(layers.Flatten())\n","model.add(layers.Dense(1024))\n","model.add(layers.Dropout(0.5))\n","model.add(layers.Dense(11,activation='sigmoid'))"],"metadata":{"id":"RYY1a2MO6vWR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sXAi5fwyByhz","executionInfo":{"status":"ok","timestamp":1649701254408,"user_tz":240,"elapsed":453,"user":{"displayName":"Emmanuel Okafor","userId":"10399249480681526142"}},"outputId":"e628a17c-a060-4b8a-e25b-3fb71782a52f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," zero_padding2d_8 (ZeroPaddi  (None, 130, 45, 1)       0         \n"," ng2D)                                                           \n","                                                                 \n"," conv2d_8 (Conv2D)           (None, 130, 45, 32)       320       \n","                                                                 \n"," zero_padding2d_9 (ZeroPaddi  (None, 132, 47, 32)      0         \n"," ng2D)                                                           \n","                                                                 \n"," conv2d_9 (Conv2D)           (None, 132, 47, 32)       9248      \n","                                                                 \n"," max_pooling2d_3 (MaxPooling  (None, 44, 15, 32)       0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_4 (Dropout)         (None, 44, 15, 32)        0         \n","                                                                 \n"," zero_padding2d_10 (ZeroPadd  (None, 46, 17, 32)       0         \n"," ing2D)                                                          \n","                                                                 \n"," conv2d_10 (Conv2D)          (None, 46, 17, 64)        18496     \n","                                                                 \n"," zero_padding2d_11 (ZeroPadd  (None, 48, 19, 64)       0         \n"," ing2D)                                                          \n","                                                                 \n"," conv2d_11 (Conv2D)          (None, 48, 19, 64)        36928     \n","                                                                 \n"," max_pooling2d_4 (MaxPooling  (None, 16, 6, 64)        0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_5 (Dropout)         (None, 16, 6, 64)         0         \n","                                                                 \n"," zero_padding2d_12 (ZeroPadd  (None, 18, 8, 64)        0         \n"," ing2D)                                                          \n","                                                                 \n"," conv2d_12 (Conv2D)          (None, 18, 8, 128)        73856     \n","                                                                 \n"," zero_padding2d_13 (ZeroPadd  (None, 20, 10, 128)      0         \n"," ing2D)                                                          \n","                                                                 \n"," conv2d_13 (Conv2D)          (None, 20, 10, 128)       147584    \n","                                                                 \n"," max_pooling2d_5 (MaxPooling  (None, 6, 3, 128)        0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_6 (Dropout)         (None, 6, 3, 128)         0         \n","                                                                 \n"," zero_padding2d_14 (ZeroPadd  (None, 8, 5, 128)        0         \n"," ing2D)                                                          \n","                                                                 \n"," conv2d_14 (Conv2D)          (None, 6, 3, 256)         295168    \n","                                                                 \n"," zero_padding2d_15 (ZeroPadd  (None, 8, 5, 256)        0         \n"," ing2D)                                                          \n","                                                                 \n"," conv2d_15 (Conv2D)          (None, 6, 3, 256)         590080    \n","                                                                 \n"," global_max_pooling2d_1 (Glo  (None, 256)              0         \n"," balMaxPooling2D)                                                \n","                                                                 \n"," flatten_1 (Flatten)         (None, 256)               0         \n","                                                                 \n"," dense_2 (Dense)             (None, 1024)              263168    \n","                                                                 \n"," dropout_7 (Dropout)         (None, 1024)              0         \n","                                                                 \n"," dense_3 (Dense)             (None, 11)                11275     \n","                                                                 \n","=================================================================\n","Total params: 1,446,123\n","Trainable params: 1,446,123\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["from tensorflow.keras import optimizers;\n","import numpy as np\n","opt = optimizers.Adam(lr = 0.001);\n","batch_size = 128\n","rawdata = tf.data.TFRecordDataset(\"/content/drive/MyDrive/ML Project/nsynth-test.tfrecord\")\n","rawdata\n","import numpy as np\n","from scipy.io import wavfile\n","import librosa\n","import sys\n","\n","def extract_from_file(r, count, seconds=4):\n","\t# Read the data\n","\t# Convert to a mono signal by taking the mean of the left and right channels\n","\taudio = r['audio'].numpy()\n","\t# Downsample from 44,100 Hz to 22,050 \n","\taudio = audio[np.arange(0, audio.size, 2)]\n","\t# Normalize by dividing the time-domain signal with its maximum value\n","\taudio /= np.max(np.abs(audio))\n","\t# Remove single dimensions\n","\taudio = np.squeeze(audio)\n","\t# Compute Short Time Fourier Transform\n","\tstft = np.abs(librosa.stft(audio, win_length=1024, hop_length=512,\n","\t\t\tcenter=True))\n","\t# Convert to Mel Spectogram\n","\tmel_spec = librosa.feature.melspectrogram(S=stft, sr=22050, n_mels=128)\n","\t\n","\tprint(mel_sepc)\n","\n","\tfeatures = {}\n","\n","\tfeatures[\"filename\"] = count\n","\tfeatures[\"mspec\"]    = mspecs\n","\tfeatures[\"labels\"]   = int(r[\"instrument_family\"])\n","\treturn features\n","\n","def _parseme(raw_audio_record):\n","\tfeature_description = {\n","\t    'note': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n","\t    'note_str': tf.io.FixedLenFeature([], tf.string, default_value=''),\n","\t    'instrument': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n","\t    'instrument_str': tf.io.FixedLenFeature([], tf.string, default_value=''),\n","\t    'pitch': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n","\t    'velocity': tf.io.FixedLenFeature([], tf.int64,default_value=0),\n","\t    'sample_rate': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n","\t    'audio': tf.io.FixedLenSequenceFeature([], tf.float32,  allow_missing=True, default_value=0.0),\n","\t    'qualities': tf.io.FixedLenSequenceFeature([], tf.int64, allow_missing=True, default_value=0),\n","\t    'qualities_str': tf.io.FixedLenSequenceFeature([], tf.string, allow_missing=True, default_value=''),\n","\t    'instrument_family': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n","\t    'instrument_family_str': tf.io.FixedLenFeature([], tf.string, default_value=''),\n","\t    'instrument_source': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n","\t    'instrument_source_str': tf.io.FixedLenFeature([], tf.string, default_value='')     \n","\t}\n","\n","\treturn tf.io.parse_single_example(raw_audio_record, feature_description)\n","\n","#for record in rawdata.take(1):\n","#\tx = record\n","\n","ar = rawdata.map(_parseme)\n","count = 0\n","for r in ar.take(1):\n","\tprint(r[\"sample_rate\"])\n","\tprint(len(r[\"audio\"].numpy()))\n"," \n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DGrS0lTaAzf7","executionInfo":{"status":"ok","timestamp":1649723059982,"user_tz":240,"elapsed":541,"user":{"displayName":"Emmanuel Okafor","userId":"10399249480681526142"}},"outputId":"30de0bc9-581a-4f59-c99e-d1d6a67fca6e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(16000, shape=(), dtype=int64)\n","64000\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]}]},{"cell_type":"code","source":["import numpy as np\n","from scipy.io import wavfile\n","import librosa\n","import sys\n","import os\n","label_map = {\"cel\" : 0, \"cla\" : 1, \"flu\" : 2, \"gac\" : 3, \"gel\" : 4, \"org\" : 5,\n","        \"pia\" : 6, \"sax\" : 7, \"tru\" : 8, \"vio\" : 9, \"voi\" : 10}\n","def extract_from_file(filename, seconds=1):\n","    \"\"\"Extracts the mel-spectogram from the input file\n","    Args:\n","        filename (str): the name of the input file\n","        seconds  (int): lenght of audio excerpt in seconds\n","    Returns:\n","        features (dict): contains the filename, the mono audio signal, the STFT,\n","                         the mspec and the labels\n","    \"\"\"\n","    # Read the data\n","    fs, audio = wavfile.read(filename)\n","\n","    # Convert to a mono signal by taking the mean of the left and right channels\n","\n","    # Downsample from 44,100 Hz to 22,050 Hz\n","    audio = np.sin(audio)\n","    print(audio)\n","    audio = audio[np.arange(0, audio.size, 2)]\n","  \n","    # Normalize by dividing the time-domain signal with its maximum value\n","    audio /= np.max(np.abs(audio))\n","    # Remove single dimensions\n","    audio = np.squeeze(audio)\n","\n","    # Compute Short Time Fourier Transform\n","    stft = np.abs(librosa.stft(audio, win_length=1024, hop_length=512,\n","        center=True))\n","    # Convert to Mel Spectogram\n","    mel_spec = librosa.feature.melspectrogram(S=stft, sr=fs/2, n_mels=128)\n","    # Take the natural logarithm of the Mel Spectogram\n","    ln_mel_spec = np.log(mel_spec + np.finfo(float).eps)\n","\n","    # Segementation of the spectogram\n","    seg_dur = 43 * seconds\n","    spec_list = []\n","    for idx in range(0, ln_mel_spec.shape[1] - seg_dur + 1, seg_dur):\n","        spec_list.append(ln_mel_spec[:, idx : (idx + seg_dur)])\n","    mspecs = np.expand_dims(np.array(spec_list), axis=1)\n","    print(mspecs)\n","    features = {}\n","\n","    features[\"filename\"] = filename[:-4]\n","    features[\"mspec\"]    = mspecs\n","    features[\"labels\"]   = np.zeros([11])\n","\n","    with open(filename[:-4] + '.txt', 'r') as fp:\n","        lines = fp.readlines()\n","        for l in lines:\n","            features[\"labels\"][label_map[l[:3]]] = 1\n","\n","    return features\n","features = []\n","folder = \"/content/drive/MyDrive/ML Project/nsynth-test.jsonwav.tar.gz (Unzipped Files)/nsynth-test/audio/\"\n","for root, dirs, files in os.walk(folder):\n","    total_files = len(files)/2\n","\n","    count = 0\n","    for file in files:\n","        print(file)\n","        if file.endswith('.wav'):\n","            count += 1\n","            feat = extract_from_file(folder+file)\n","            features.append(feat)\n","\n","np.save(\"%s_features\" % folder[:23], features)\n","\n","\n","\n"],"metadata":{"id":"ryHn0EEVODfx","colab":{"base_uri":"https://localhost:8080/","height":674},"executionInfo":{"status":"error","timestamp":1649725180022,"user_tz":240,"elapsed":391,"user":{"displayName":"Emmanuel Okafor","userId":"10399249480681526142"}},"outputId":"518bdbb4-cada-4872-e42b-5f9584fef93e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["organ_electronic_113-039-025.wav\n","[0. 0. 0. ... 0. 0. 0.]\n","[[[[1.2029198  0.9367139  0.5946519  ... 1.3322008  0.736823\n","    0.64751315]\n","   [1.0102193  1.2699876  1.5359535  ... 1.0776055  1.220863\n","    1.0907426 ]\n","   [0.6224446  1.4160701  0.67703104 ... 0.9604098  1.7218243\n","    1.0490135 ]\n","   ...\n","   [0.26113904 0.99049515 1.2125094  ... 1.1104779  1.0853425\n","    1.1534326 ]\n","   [0.41651762 1.4034909  1.283678   ... 0.84723336 0.9904897\n","    0.9938197 ]\n","   [0.4557984  1.3056159  1.0532019  ... 1.0895808  1.0207883\n","    1.2342778 ]]]]\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-47-9b9d076a3421>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.wav'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mfeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-47-9b9d076a3421>\u001b[0m in \u001b[0;36mextract_from_file\u001b[0;34m(filename, seconds)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m]\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/ML Project/nsynth-test.jsonwav.tar.gz (Unzipped Files)/nsynth-test/audio/organ_electronic_113-039-025.txt'"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"uYKuwvj5EUtn"},"execution_count":null,"outputs":[]}]}